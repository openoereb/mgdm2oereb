# General

We define the process of transformation in this project as a pipeline (or job) which executes single steps (or task) in a
defined order and composition.

In general the pipline follows this scheme for all datasets:
```mermaid
flowchart
direction TB

input[Client sends zip]
job_start[Start]
job_info[["Job info (XML?)"]]
unpack[unpack]
input_check[Input check]
input_ili_validation[Input ili validation]
trafo[XSL-Transformation]
output_ili_validation[Output ili validation]
publish[S3 Bucket publish]
publish_job_info[S3 Bucket job info]
job_finish["END"]

input --> job_start

job_start -->|"Job UUID"| job_info
job_start --> unpack

unpack -->|"Task UUID + task info"| job_info
unpack --> input_check

input_check --> input_ili_validation
input_check -->|"Task UUID + task info"| job_info

input_ili_validation --> trafo
input_ili_validation -->|"Task UUID + task info"| job_info

trafo --> output_ili_validation
trafo -->|"Task UUID + task info"| job_info


output_ili_validation --> publish
output_ili_validation -->|"Task UUID + task info"| job_info

job_info --> publish_job_info
publish_job_info --> job_finish
publish --> job_finish

```

We see a parallel flow of things happen aside the actual pipelines. This is about keeping track of things.

Each step should write information of input/output and especially errors to a XML file. This file contains the life cycle
of the pipeline in the end and is published to a semi public bucket which exists per user. The XML should be minimalistic
and only be used to get information about the states. It should be wrapped as a snippet for a feed standard (RSS/ATOM) to be
easily merged into a feed by external service. The job info must contain UUID's für the pipeline run and for each task as well.
So these must be generated by Pipeline START and by each task.
A possible addition in later version might also include the artifacts of the tasks to be able to debug failing jobs.

# Pipeline "Client delivers Catalogs"

```mermaid
flowchart

direction TB

input[[Client sends zip]]
prepare([unpack])
input_check([are expected files there])
input_check_ili([MGDM ili validation])

trafo([XSL-Transformation])
MGDM_X[[MGDM X]]
view_service_catalog[[View service catalog]]
document_catalog[["Document catalog (incl. offices)"]]
OEREB_TRSFR[[Data as ÖREB transfer model]]
meta_data_generation([Produce metadata])

output_check_ili([ÖREB ili validation])
output_check_ili_log[[Log file]]
output_ili_hash[[MD5 Hash in TXT]]
output_ili_feed_xml[[Snippet representing XML feed element]]



publish[S3 Bucket publish]
job_info[S3 Bucket job info]

input --> prepare
prepare --> input_check
input_check --> MGDM_X
input_check --> view_service_catalog
input_check --> document_catalog
MGDM_X --> input_check_ili
MGDM_X --> trafo
view_service_catalog --> trafo
document_catalog --> trafo

trafo --> OEREB_TRSFR
OEREB_TRSFR --> output_check_ili
output_check_ili --> output_check_ili_log

meta_data_generation --> output_ili_hash
meta_data_generation --> output_ili_feed_xml
OEREB_TRSFR --> meta_data_generation
output_check_ili_log --> publish
OEREB_TRSFR --> publish
output_ili_hash --> publish
output_ili_feed_xml --> publish
  
```

# Pipeline "Client delivers only links to documents (ÖREBlex)"

```mermaid
flowchart
  
direction TB

input[[Client sends zip]]
prepare([unpack])
input_check([are expected files there])
input_check_ili([MGDM ili validation])

trafo([XSL-Transformation])
MGDM_X[[MGDM X]]
view_service_catalog[[View service catalog]]
trafo_oereb_lex_links([Extract links from MGDM])
oereblex_link_list[["Download links for ÖREBlex"]]
oereblex_link_download(["Download ÖREBlex XML snippets"])
oereblex_link_snippets[["ÖREBlex XML snippets"]]
trafo_oereb_lex([Generate catalog])
document_catalog[["Document catalog (incl. offices)"]]
OEREB_TRSFR[[Data as ÖREB transfer model]]
meta_data_generation([Produce metadata])

output_check_ili([ÖREB ili validation])
output_check_ili_log[[Log file]]
output_ili_hash[[MD5 Hash in TXT]]
output_ili_feed_xml[[Snippet Representing XML Feedelement]]

publish([S3 Bucket])


input --> prepare
prepare --> input_check
input_check --> MGDM_X
input_check --> view_service_catalog

MGDM_X --> trafo_oereb_lex_links
trafo_oereb_lex_links --> oereblex_link_list
oereblex_link_list --> oereblex_link_download
oereblex_link_download --> oereblex_link_snippets
oereblex_link_snippets --> trafo_oereb_lex
trafo_oereb_lex --> document_catalog
MGDM_X --> trafo
MGDM_X --> input_check_ili
view_service_catalog --> trafo
document_catalog --> trafo
trafo --> OEREB_TRSFR
OEREB_TRSFR --> output_check_ili
output_check_ili --> output_check_ili_log

meta_data_generation --> output_ili_hash
meta_data_generation --> output_ili_feed_xml
OEREB_TRSFR --> meta_data_generation
output_check_ili_log --> publish
OEREB_TRSFR --> publish

output_ili_hash --> publish
output_ili_feed_xml --> publish

```

